{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sympy import sympify\n",
    "import sympy as sp\n",
    "import torch\n",
    "from torchengine import AnalyticalSetSympy, Function, EliminateAnalysis, ParallelAnalysis, EliminateAnalysisMergeResiduals\n",
    "import numpy as np\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{:0.2f}\".format(x).rstrip('0').rstrip('.')})\n",
    "import re\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "def extract_number(string):\n",
    "    return int(re.search(r'\\d+', string).group())\n",
    "\n",
    "def process_expression(exprstr, symb_str_mapping):\n",
    "    exprsympy = sympify(exprstr, locals=symb_str_mapping)\n",
    "    # free_symbols returns a set which is not ordered\n",
    "    sorted_symbols = sorted(exprsympy.free_symbols, key=lambda s: s.name)\n",
    "    for symbol in sorted_symbols:\n",
    "        if str(symbol) not in symb_str_mapping:\n",
    "            symb_str_mapping[str(symbol)] = symbol\n",
    "    return exprsympy\n",
    "\n",
    "def process_json(data, symb_str_mapping=None):\n",
    "    functional_sets = data[\"functional_sets\"]\n",
    "    \n",
    "    symb_str_mapping = symb_str_mapping if symb_str_mapping else {}\n",
    "    analysismap = []\n",
    "    \n",
    "    for functional_set in functional_sets:\n",
    "        analysis_str = functional_set['analysis']\n",
    "        output_var_str= functional_set['functionalvar']\n",
    "        analysis = process_expression(analysis_str, symb_str_mapping)\n",
    "        if output_var_str not in symb_str_mapping:\n",
    "            outputvar = sp.Symbol(output_var_str)\n",
    "            symb_str_mapping[output_var_str] = outputvar\n",
    "        else:\n",
    "            outputvar = symb_str_mapping[output_var_str]\n",
    "        analysismap.append((analysis, outputvar))\n",
    "    \n",
    "    return analysismap, symb_str_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if file exists or not return True/False\n",
    "import os\n",
    "def load_file(file_name):\n",
    "    file_path = f'../applications/data/{file_name}.json'\n",
    "    os.path.isfile(file_path)\n",
    "    with open(file_path, 'r') as file:\n",
    "        json_str = file.read()\n",
    "    data = json.loads(json_str)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "symb_str_mapping = {}\n",
    "all_analyses = {}\n",
    "disciplines = ['pearl_geom','pearl_hydro', 'pearl_mass','pearl_prop','pearl_comms','pearl_power', 'pearl_solar', 'pearl_battery']\n",
    "flattened_output = []\n",
    "equality_constraints_sympy = []\n",
    "for file_name in disciplines:\n",
    "    data = load_file(file_name)\n",
    "    flattened_output += data['functional_sets']\n",
    "    equality_constraints_sympy += [process_expression(elt, symb_str_mapping) for elt in data.get('equality_constraints',[])]\n",
    "    analysismap, symb_str_mapping = process_json(data, symb_str_mapping)\n",
    "    all_analyses[file_name] = analysismap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = {elt: torch.tensor([int(i)]) for i, elt in \n",
    "            enumerate(symb_str_mapping.values())}\n",
    "sets ={}\n",
    "for file_name, analysismap in all_analyses.items():\n",
    "        sets[file_name] = {idx:AnalyticalSetSympy(analysis, outputvar=outputvar, indices=indices) for idx,(analysis,outputvar) in enumerate(analysismap)}\n",
    "equality_constraints = [Function((\n",
    "        sorted(expr.free_symbols, key=lambda s: s.name),\n",
    "        sp.lambdify(sorted(expr.free_symbols, key=lambda s: s.name), expr, torch),  \n",
    "        ), indices=indices) for expr in equality_constraints_sympy]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partitioned analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_order = [{1,2,3}, {4,5}, {6}] # a feedforward partition is equivalent to splitting up the sets, however the shared vars will be different depending on the partition (in the extreme all vars will be shared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_partition_order = []\n",
    "flat_sets = {}\n",
    "for file_name, subsets in sets.items():\n",
    "    custom_partition_order.append(())\n",
    "    for elt in subsets.values():\n",
    "        flatidx = len(flat_sets)\n",
    "        flat_sets[flatidx] = elt\n",
    "        custom_partition_order[-1] += (flatidx,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_order = custom_partition_order\n",
    "#partition_order = [{idx} for idx in flat_sets.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequential = {}\n",
    "for partidx, elt in enumerate(partition_order):\n",
    "    if len(elt) ==1:\n",
    "        sequential[partidx] = flat_sets[next(iter(elt))].analysis\n",
    "    else:\n",
    "        sequential[partidx] = EliminateAnalysis([flat_sets[idx].analysis for idx in elt], [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "xvalsdict = load_file('pearl_params')\n",
    "x0 = torch.zeros(len(indices), dtype=torch.float64)\n",
    "for key, val in indices.items():\n",
    "    x0[val] = xvalsdict[str(key)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 0.2, 0.3, 1.25, 2, 0.45, 0.5, 2, 1, 9.8, 1000, 1, 1, 1, 0.5,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 10, 1, 1, 50, 50, 1, 700, 2700, 1, 1, 0.75,\n",
       "       1, 1, 300000000, 2200000000, 1, 27, 32, 1, 0.55, 1, 5.3, 1,\n",
       "       6378000, 600000, 1, 1, 38.9, 0.93, 0.79, 0.93, 85000000, 135, 0, 1,\n",
       "       3600, 1, 50, 86400, 1, 3600, 1, 1900, 1, 1, 43200, 1, 1, 1, 43200,\n",
       "       1, 0.9, 1, 0.05, 0.27, 800, 0.96, 0.7, 1, 0.85, 1, 5, 720000])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x0.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_formatter(x):\n",
    "    if abs(x) < 0.01:\n",
    "        return \"{:.2e}\".format(x).replace('+0', '')\n",
    "    elif abs(x) > 10000:\n",
    "        return \"{:.2e}\".format(x).replace('+0', '')\n",
    "    else:\n",
    "        return \"{:.3f}\".format(x).rstrip('0').rstrip('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_solar D_f alpha d   D_d  D_s h_f  t_d t_s V_d g   rho_w F_B F_W K_B t_f K_G I B_M G_M C_33 A_33 m_platform \\omega_0 eta_solar m_solar m_batt m_comms m_prop m_struct rho rho_h S_w C_d eta_m v P_move c      f      l e_t theta_t L_pt eta_parab G_t D_r G_r R_e    h      S L_s E_N  L_a   L_l  L_p   R      T_s k        P_comms t_move E_move P_hotel t_mission E_hotel t_comms E_comms E_AUV G E_service t_service P_service E_required E_recharge t_recharge P_recharge I_deg L_solar d_deg eta_s phi_s theta DOD N_batt eta_battery C m_battzero mu_battery\n",
      "1       2   0.2   0.3 1.25 2   0.45 0.5 2   1   9.8 1000  1   1   1   0.5 1   1 1   1   1    1    1          1        10        1       1      50      50     1        700 2700  1   1   0.75  1 1      3.00e8 2.20e9 1 27  32      1    0.55      1   5.3 1   6.38e6 6.00e5 1 1   38.9 0.933 0.79 0.933 8.50e7 135 1.38e-23 1       3600   1      50      8.64e4    1       3600    1       1900  1 1         4.32e4    1         1          1          4.32e4     1          0.9   1       0.05  0.27  800   0.96  0.7 1      0.85        1 5          7.20e5    \n",
      "1       2   0.2   0.4 1.25 2   0.45 0.5 2   1   9.8 1000  1   1   1   0.5 1   1 1   1   1    1    1          1        10        1       1      50      50     1        700 2700  1   1   0.75  1 1      3.00e8 2.20e9 1 27  32      1    0.55      1   5.3 1   6.38e6 6.00e5 1 1   38.9 0.933 0.79 0.933 8.50e7 135 1.38e-23 1       3600   1      50      8.64e4    1       3600    1       1900  1 1         4.32e4    1         1          1          4.32e4     1          0.9   1       0.05  0.27  800   0.96  0.7 1      0.85        1 5          7.20e5    \n"
     ]
    }
   ],
   "source": [
    "matrix =([str(k) for k in indices.keys()], x0, sequential[0](x0))\n",
    "col_widths = [max(len(custom_formatter(row1)), len(custom_formatter(row2)), len(name)) for name,row1,row2 in zip(*matrix)]\n",
    "print(\" \".join(\"{:<{}}\".format(name, width) for name, width in zip(matrix[0], col_widths)))\n",
    "for row in matrix[1:]:\n",
    "    print(\" \".join(\"{:<{}}\".format(custom_formatter(num), width) for num, width in zip(row, col_widths)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get shared variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3, 7, 13, 22, 26, 36, 58, 71]\n"
     ]
    }
   ],
   "source": [
    "sharedvars = []\n",
    "for _, s1 in sequential.items():\n",
    "    for _, s2 in sequential.items():\n",
    "        svars = [elt1 for elt1 in s1.structure[1] for elt2 in s2.structure[0] if elt1 == elt2 and elt1 not in sharedvars]\n",
    "        sharedvars+=svars\n",
    "print(sorted(torch.tensor(sharedvars).tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get feedback vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 7, 22, 26]\n"
     ]
    }
   ],
   "source": [
    "all_sequential = EliminateAnalysis(list(sequential.values()), [])\n",
    "couplingvars = [elt for elt in all_sequential.structure[0] if elt in all_sequential.structure[1]]\n",
    "print(sorted(torch.tensor(couplingvars).tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 [59, 36]\n",
      "63 [61, 62]\n",
      "65 [64, 58]\n",
      "68 [66, 67]\n",
      "70 [66, 67, 69]\n",
      "71 [61, 62, 66, 67, 59, 36, 64, 58]\n"
     ]
    }
   ],
   "source": [
    "for key,val in sequential[5].structure_full.items():\n",
    "    print(key,val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "couplingvars = [0,7,26]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 [2, 1]\n",
      "9 [8, 6, 4, 5, 7, 1]\n",
      "12 [10, 11, 8, 6, 4, 5, 7, 1]\n",
      "13 [10, 11, 8, 6, 4, 5, 7, 1]\n",
      "14 [8, 4, 1, 5, 6, 7]\n",
      "16 [8, 4, 1, 15, 5, 7]\n",
      "17 [1]\n",
      "18 [1, 8, 6, 4, 5, 7]\n",
      "19 [1, 8, 6, 4, 5, 7, 15]\n",
      "20 [10, 1, 11]\n",
      "21 [5, 4, 1, 11]\n",
      "23 [10, 1, 11, 5, 4, 22]\n",
      "22 [10, 11, 8, 6, 4, 5, 7, 1]\n",
      "25 [0, 24]\n",
      "29 [28, 0, 24, 26, 10, 11, 8, 6, 4, 5, 7, 1, 27]\n",
      "7 [8, 4, 30, 1, 15, 5, 28, 0, 24, 26, 10, 11, 6, 7, 27, 31]\n",
      "32 [5, 6, 4, 8, 30, 1, 15, 28, 0, 24, 26, 10, 11, 7, 27, 31]\n",
      "36 [5, 6, 4, 8, 30, 1, 15, 28, 0, 24, 26, 10, 11, 7, 27, 31, 34, 33, 35]\n",
      "39 [37, 38]\n",
      "42 [40, 41]\n",
      "44 [37, 38, 2, 1, 43, 40, 41]\n",
      "46 [37, 38, 45, 43]\n",
      "49 [47, 48]\n",
      "50 [37, 38, 47, 48]\n",
      "58 [37, 38, 2, 1, 43, 40, 41, 45, 57, 55, 54, 53, 51, 56, 52, 47, 48]\n",
      "60 [59, 5, 6, 4, 8, 30, 1, 15, 28, 0, 24, 26, 10, 11, 7, 27, 31, 34, 33, 35]\n",
      "63 [61, 62]\n",
      "65 [64, 37, 38, 2, 1, 43, 40, 41, 45, 57, 55, 54, 53, 51, 56, 52, 47, 48]\n",
      "68 [66, 67]\n",
      "70 [66, 67, 69]\n",
      "71 [61, 62, 66, 67, 59, 5, 6, 4, 8, 30, 1, 15, 28, 0, 24, 26, 10, 11, 7, 27, 31, 34, 33, 35, 64, 37, 38, 2, 43, 40, 41, 45, 57, 55, 54, 53, 51, 56, 52, 47, 48]\n",
      "72 [61, 62, 66, 67, 59, 5, 6, 4, 8, 30, 1, 15, 28, 0, 24, 26, 10, 11, 7, 27, 31, 34, 33, 35, 64, 37, 38, 2, 43, 40, 41, 45, 57, 55, 54, 53, 51, 56, 52, 47, 48]\n",
      "74 [73, 61, 62, 66, 67, 59, 5, 6, 4, 8, 30, 1, 15, 28, 0, 24, 26, 10, 11, 7, 27, 31, 34, 33, 35, 64, 37, 38, 2, 43, 40, 41, 45, 57, 55, 54, 53, 51, 56, 52, 47, 48]\n",
      "0 [78, 73, 61, 62, 66, 67, 59, 5, 6, 4, 8, 30, 1, 15, 28, 0, 24, 26, 10, 11, 7, 27, 31, 34, 33, 35, 64, 37, 38, 2, 43, 40, 41, 45, 57, 55, 54, 53, 51, 56, 52, 47, 48, 77, 75, 80, 76, 79]\n",
      "84 [61, 62, 66, 67, 59, 5, 6, 4, 8, 30, 1, 15, 28, 0, 24, 26, 10, 11, 7, 27, 31, 34, 33, 35, 64, 37, 38, 2, 43, 40, 41, 45, 57, 55, 54, 53, 51, 56, 52, 47, 48, 82, 81, 83]\n",
      "26 [85, 86, 61, 62, 66, 67, 59, 5, 6, 4, 8, 30, 1, 15, 28, 0, 24, 26, 10, 11, 7, 27, 31, 34, 33, 35, 64, 37, 38, 2, 43, 40, 41, 45, 57, 55, 54, 53, 51, 56, 52, 47, 48, 82, 81, 83]\n"
     ]
    }
   ],
   "source": [
    "for key,val in all_sequential.structure_full.items():\n",
    "    print(key, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\omega_{0}$"
      ],
      "text/plain": [
       "\\omega_0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(indices.keys())[23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  4,  5,  6,  7,  8, 10, 11, 15, 22, 24, 26, 27, 28, 30, 31,\n",
       "        33, 34, 35, 37, 38, 40, 41, 43, 45, 47, 48, 51, 52, 53, 54, 55, 56, 57,\n",
       "        59, 61, 62, 64, 66, 67, 69, 73, 75, 76, 77, 78, 79, 80, 81, 82, 83, 85,\n",
       "        86])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_sequential.structure[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_solar D_f alpha d   D_d  D_s h_f  t_d t_s V_d g   rho_w F_B F_W K_B t_f K_G I B_M G_M C_33 A_33 m_platform \\omega_0 eta_solar m_solar m_batt m_comms m_prop m_struct rho rho_h S_w C_d eta_m v P_move c      f      l e_t theta_t L_pt eta_parab G_t D_r G_r R_e    h      S L_s E_N  L_a   L_l  L_p   R      T_s k        P_comms t_move E_move P_hotel t_mission E_hotel t_comms E_comms E_AUV G E_service t_service P_service E_required E_recharge t_recharge P_recharge I_deg L_solar d_deg eta_s phi_s theta DOD N_batt eta_battery C m_battzero mu_battery\n",
      "1       2   0.2   0.3 1.25 2   0.45 0.5 2   1   9.8 1000  1   1   1   0.5 1   1 1   1   1    1    1          1        10        1       1      50      50     1        700 2700  1   1   0.75  1 1      3.00e8 2.20e9 1 27  32      1    0.55      1   5.3 1   6.38e6 6.00e5 1 1   38.9 0.933 0.79 0.933 8.50e7 135 1.38e-23 1       3600   1      50      8.64e4    1       3600    1       1900  1 1         4.32e4    1         1          1          4.32e4     1          0.9   1       0.05  0.27  800   0.96  0.7 1      0.85        1 5          7.20e5    \n",
      "1       2   0.2   0.4 1.25 2   0.45 0.5 2   1   9.8 1000  1   1   1   0.5 1   1 1   1   1    1    1          1        10        1       1      50      50     1        700 2700  1   1   0.75  1 1      3.00e8 2.20e9 1 27  32      1    0.55      1   5.3 1   6.38e6 6.00e5 1 1   38.9 0.933 0.79 0.933 8.50e7 135 1.38e-23 1       3600   1      50      8.64e4    1       3600    1       1900  1 1         4.32e4    1         1          1          4.32e4     1          0.9   1       0.05  0.27  800   0.96  0.7 1      0.85        1 5          7.20e5    \n"
     ]
    }
   ],
   "source": [
    "matrix =([str(k) for k in indices.keys()], x0, sequential[0](x0))\n",
    "col_widths = [max(len(custom_formatter(row1)), len(custom_formatter(row2)), len(name)) for name,row1,row2 in zip(*matrix)]\n",
    "print(\" \".join(\"{:<{}}\".format(name, width) for name, width in zip(matrix[0], col_widths)))\n",
    "for row in matrix[1:]:\n",
    "    print(\" \".join(\"{:<{}}\".format(custom_formatter(num), width) for num, width in zip(row, col_widths)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run with fixed parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective = Function(((symb_str_mapping['m_platform'],), lambda m: m), indices=indices)\n",
    "ineq_constraint = EliminateAnalysisMergeResiduals([], [\n",
    "    Function(((symb_str_mapping['h_f'],symb_str_mapping['t_f']), lambda hf,tf: hf/(0.9*tf)-1), indices=indices),\n",
    "    Function(((symb_str_mapping['D_s'],symb_str_mapping['D_f']), lambda Ds,Df: Ds/(0.9*Df)-1), indices=indices),\n",
    "    Function(((symb_str_mapping['D_s'],symb_str_mapping['D_d']), lambda Ds,Dd: Ds/(0.9*Dd)-1), indices=indices),\n",
    "    Function(((symb_str_mapping['P_move'],), lambda P: -P), indices=indices),\n",
    "    Function(((symb_str_mapping['t_d'],), lambda td: -td/0.1+1), indices=indices),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 6, 15,  5,  1,  4, 36,  7]), tensor([]))"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ineq_constraint.structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf_eval = ParallelAnalysis([all_sequential], [objective]+[ineq_constraint]+equality_constraints, sharedvars=couplingvars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [2,3,10,11,23,24,26,27,28,29,30,31,33,34,37,38,39,40,41,42,43,45,47,48,51,52,53,54,55,56,57,59,61,62,64,66,67,69,73,75,76,77,78,79,80,81,82,83,85,86]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([alpha, d, g, rho_w, \\omega_0, eta_solar, m_batt, m_comms, m_prop,\n",
       "       m_struct, rho, rho_h, C_d, eta_m, c, f, l, e_t, theta_t, L_pt,\n",
       "       eta_parab, D_r, R_e, h, E_N, L_a, L_l, L_p, R, T_s, k, t_move,\n",
       "       P_hotel, t_mission, t_comms, E_AUV, G, t_service, t_recharge,\n",
       "       I_deg, L_solar, d_deg, eta_s, phi_s, theta, DOD, N_batt,\n",
       "       eta_battery, m_battzero, mu_battery], dtype=object)"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([list(indices.keys())[elt] for elt in params])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 ['D_f']\n",
      "9 ['t_s', 'h_f', 'D_d', 'D_s', 't_d', 'D_f']\n",
      "12 ['t_s', 'h_f', 'D_d', 'D_s', 't_d', 'D_f']\n",
      "13 ['t_s', 'h_f', 'D_d', 'D_s', 't_d', 'D_f']\n",
      "14 ['t_s', 'D_d', 'D_f', 'D_s', 'h_f', 't_d']\n",
      "16 ['t_s', 'D_d', 'D_f', 't_f', 'D_s', 't_d']\n",
      "17 ['D_f']\n",
      "18 ['D_f', 't_s', 'h_f', 'D_d', 'D_s', 't_d']\n",
      "19 ['D_f', 't_s', 'h_f', 'D_d', 'D_s', 't_d', 't_f']\n",
      "20 ['D_f']\n",
      "21 ['D_s', 'D_d', 'D_f']\n",
      "23 ['D_f', 'D_s', 'D_d', 'm_platform']\n",
      "22 ['t_s', 'h_f', 'D_d', 'D_s', 't_d', 'D_f']\n",
      "25 ['A_solar']\n",
      "29 ['A_solar', 't_s', 'h_f', 'D_d', 'D_s', 't_d', 'D_f']\n",
      "7 ['t_s', 'D_d', 'D_f', 't_f', 'D_s', 'A_solar', 'h_f', 't_d']\n",
      "32 ['D_s', 'h_f', 'D_d', 't_s', 'D_f', 't_f', 'A_solar', 't_d']\n",
      "36 ['D_s', 'h_f', 'D_d', 't_s', 'D_f', 't_f', 'A_solar', 't_d', 'v']\n",
      "39 []\n",
      "42 []\n",
      "44 ['D_f']\n",
      "46 []\n",
      "49 []\n",
      "50 []\n",
      "58 ['D_f']\n",
      "60 ['D_s', 'h_f', 'D_d', 't_s', 'D_f', 't_f', 'A_solar', 't_d', 'v']\n",
      "63 []\n",
      "65 ['D_f']\n",
      "68 []\n",
      "70 []\n",
      "71 ['D_s', 'h_f', 'D_d', 't_s', 'D_f', 't_f', 'A_solar', 't_d', 'v']\n",
      "72 ['D_s', 'h_f', 'D_d', 't_s', 'D_f', 't_f', 'A_solar', 't_d', 'v']\n",
      "74 ['D_s', 'h_f', 'D_d', 't_s', 'D_f', 't_f', 'A_solar', 't_d', 'v']\n",
      "0 ['D_s', 'h_f', 'D_d', 't_s', 'D_f', 't_f', 'A_solar', 't_d', 'v']\n",
      "84 ['D_s', 'h_f', 'D_d', 't_s', 'D_f', 't_f', 'A_solar', 't_d', 'v']\n",
      "26 ['D_s', 'h_f', 'D_d', 't_s', 'D_f', 't_f', 'A_solar', 't_d', 'v']\n"
     ]
    }
   ],
   "source": [
    "for key,val in all_sequential.structure_full.items():\n",
    "    print(key, [str(list(indices.keys())[elt]) for elt in val if elt not in params])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "xvalsdict = load_file('pearl_params')\n",
    "x0 = torch.tensor([xvalsdict[str(key)] for key, val in indices.items()], dtype=torch.float64, requires_grad=True)\n",
    "coupling_idx = torch.tensor(couplingvars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf_pure = ParallelAnalysis([all_sequential], [], sharedvars=couplingvars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(A_solar, 0), (t_d, 7), (m_batt, 26)]"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(list(indices.keys())[elt],elt.item()) for elt in coupling_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., dtype=torch.float64)"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eps = 1e-5\n",
    "xn = x0 + torch.rand_like(x0)\n",
    "xcopy = xn.detach()\n",
    "((all_sequential(xcopy+eps*torch.eye(87)[:,0])-all_sequential(xcopy))/eps)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3716, dtype=torch.float64)"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_sequential(xcopy)[23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 7, 26]"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "couplingvars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2, 1]), tensor([3]))"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_sets[0].analysis.structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1413.72, 981.75, 6283.19, 3141.59, 1227.18, 3141.59, 0, 0, 0,\n",
       "        0, 0],\n",
       "       [0, 0, 0, 0, 2.22, 0, 0, -2, 0, 0, 0, 0],\n",
       "       [0, -0.56, 0, 0.56, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, -1.42, 0.89, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [7.9, -3285.1, -1685.95, -1489.35, -6671.04, -969.63, -4933.46,\n",
       "        1737.57, 0, 0.79, -35817.21, 0],\n",
       "       [0.03, -0.95, 10.08, -5.69, -9.48, -3.7, -2.84, 6.64, 0, 0, 0, 0],\n",
       "       [0, 0.18, -0.03, -0.03, -0.12, -0.02, -0.09, 0.03, 0, 0, -0.66,\n",
       "        -0],\n",
       "       [-0.01, 0.19, -2.02, 1.14, 1.9, -2.52, 0.57, -1.33, 0, -0, 0, 0],\n",
       "       [-10.35, 2.58, 1.33, 1.17, 5.25, 0.76, 3.88, -1.37, 0, -0, 28.18,\n",
       "        0],\n",
       "       [-0.07, 27.51, 14.17, 12.52, 56.06, 8.15, 41.46, -14.6, 0, -0.01,\n",
       "        300.98, 0]])"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd.functional import jacobian\n",
    "\n",
    "test_idx = [0, 1, 4, 5, 6, 7, 8, 15, 22, 24, 35, 55] #coupling_idx\n",
    "xcopy = x0.detach()\n",
    "xinit = x0[test_idx]\n",
    "\n",
    "def run_with_smaller(x):\n",
    "    xcopy[test_idx] = x\n",
    "    #out = sequential_all(xcopy[coupling_idx]\n",
    "    #out = idf_pure(xcopy)[0]\n",
    "    out = torch.cat(idf_eval(xcopy))\n",
    "    return out\n",
    "\n",
    "jacobian(run_with_smaller, xinit).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(idf_eval.structure_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_optim_functions(optim_funcs, solvefor_indices, x):\n",
    "    def eval_all(y):\n",
    "        x.requires_grad_(False)\n",
    "        x[solvefor_indices] = torch.from_numpy(y).to(x.dtype)\n",
    "        objval, ineqval, eqval, res = optim_funcs(x)\n",
    "        x.requires_grad_(True)\n",
    "        return objval.item(), -ineqval, -torch.cat((eqval, res))\n",
    "    \n",
    "    def obj_function(y):\n",
    "        objval, _, _ = eval_all(y)\n",
    "        return objval\n",
    "\n",
    "    def ineq_function(y=None):\n",
    "        _, ineqval, _ = eval_all(y)\n",
    "        return ineqval\n",
    "    \n",
    "    def eq_function(y=None):\n",
    "        _, _, eqval = eval_all(y)\n",
    "        return eqval\n",
    "    \n",
    "    def dobj(y):\n",
    "        xc = x.detach() # remove gradient tracking\n",
    "        xc[solvefor_indices] = torch.from_numpy(y).to(x.dtype)\n",
    "        dobj = jacobian(lambda w: optim_funcs(w)[0], xc).numpy()[0]\n",
    "        return dobj[solvefor_indices]\n",
    "\n",
    "    def dineq(y=None):\n",
    "        xc = x.detach()\n",
    "        xc[solvefor_indices] = torch.from_numpy(y).to(x.dtype)\n",
    "        dineq = jacobian(lambda w: optim_funcs(w)[1], xc).numpy()\n",
    "        return -dineq[:,solvefor_indices]\n",
    "    \n",
    "    def deq(y=None):\n",
    "        xc = x.detach()\n",
    "        xc[solvefor_indices] = torch.from_numpy(y).to(x.dtype)\n",
    "        deq = jacobian(lambda w: torch.cat(optim_funcs(w)[2:]), xc).numpy()\n",
    "        return -deq[:,solvefor_indices]\n",
    "\n",
    "    xguess = x[solvefor_indices].detach().numpy()\n",
    "    \n",
    "    return xguess, obj_function, ineq_function, eq_function, dobj, dineq, deq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 4, 5, 6, 7, 8, 15, 22, 35]\n",
      "[6, 15]\n",
      "[5, 1]\n",
      "[5, 4]\n",
      "[0, 1, 4, 5, 6, 7, 8, 15, 22, 35]\n",
      "[0, 1, 4, 5, 6, 7, 8, 15, 22, 35]\n",
      "[0, 1, 4, 5, 6, 7, 8, 15, 22, 35]\n",
      "[7, 0, 1, 4, 5, 6, 8, 15, 22, 35]\n",
      "[0, 1, 4, 5, 6, 7, 8, 15, 22, 35]\n",
      "[0, 1, 4, 5, 6, 7, 8, 15, 22, 35]\n"
     ]
    }
   ],
   "source": [
    "for item in idf_eval.structure_full:\n",
    "    print([elt for elt in item if elt not in params])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "xvalsdict = load_file('pearl_params')\n",
    "x0 = torch.tensor([xvalsdict[str(key)] for key, val in indices.items()], dtype=torch.float64)\n",
    "numerical_values = {'D_f': 3.7, 'D_d':1., 'D_s':0.15, 't_d':0.2, 'h_f':0.09, 't_s':0.2}\n",
    "for var, val in numerical_values.items():\n",
    "    x0[indices[sp.symbols(var)]] = val\n",
    "x0.requires_grad_(True)\n",
    "designvars = [1,4,5,8,15]#1,8,4,5,15]\n",
    "couplingvars = [0,7,26]\n",
    "othervars = []\n",
    "solvefor_indices = torch.tensor(designvars+othervars+couplingvars)\n",
    "xguess, obj_function, ineq_function, eq_function, dobj, dineq, deq = generate_optim_functions(idf_eval, solvefor_indices, x0)\n",
    "constraints = [{'type': 'eq', 'fun': eq_function, 'jac': deq}]\n",
    "constraints.append({'type': 'ineq', 'fun': ineq_function, 'jac': dineq})\n",
    "bnds_problem = [(0.1, 10) for _ in designvars]+[(0, None) for _ in othervars+couplingvars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000e+00, 0.0000e+00, 1.6667e-01, 5.1191e+03, 2.7403e+01],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eps = 1e-6\n",
    "xcopy = xguess\n",
    "testf = ineq_function\n",
    "(testf(xguess+eps*np.eye(len(xcopy))[:,1])-testf(xcopy))/eps #obj 4,6 zero gradient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0, -0, -0, -0, 0.4, -0, -0, -0],\n",
       "       [0.01, -0, -0.3, -0, -0, -0, -0, -0],\n",
       "       [-0, 0.17, -1.11, -0, -0, -0, -0, -0],\n",
       "       [2570.68, 5119.15, 118.68, 319.4, -7433.55, -9.88, 775.7, -0.99],\n",
       "       [-7.13, 27.4, 0.07, 0.03, -35.49, -0.05, 3.7, -0]])"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dineq(xguess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['D_f', 'alpha', 'D_d', 'D_s', 'h_f', 't_s', 'g', 'rho_w', 't_f',\n",
       "       'eta_solar', 'm_comms', 'm_prop', 'rho', 'rho_h', 'C_d', 'eta_m',\n",
       "       'v', 'c', 'f', 'e_t', 'theta_t', 'eta_parab', 'D_r', 'R_e', 'h',\n",
       "       'E_N', 'L_a', 'L_l', 'L_p', 'R', 'T_s', 'k', 't_move', 'P_hotel',\n",
       "       't_mission', 't_comms', 'E_AUV', 'G', 't_service', 't_recharge',\n",
       "       'I_deg', 'L_solar', 'd_deg', 'eta_s', 'phi_s', 'theta', 'DOD',\n",
       "       'N_batt', 'eta_battery', 'm_battzero', 'mu_battery'], dtype='<U11')"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = torch.tensor([elt.item() for elt in all_sequential.structure[0] if elt not in all_sequential.structure[1]])\n",
    "np.array([str(list(indices.keys())[inp]) for inp in inputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([55])"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices[symb_str_mapping['R']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['D_f', 'D_d', 'D_s', 't_s', 't_f'], ['A_solar', 't_d', 'm_batt'])"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[str(k) for k in indices.keys()][elt] for elt in designvars], [[str(k) for k in indices.keys()][elt] for elt in couplingvars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xguess = np.array([1.98, 10, 0.21, 0.19, 0.1, 0.1, 585, 0.03, 20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\johan\\miniconda3\\envs\\minimdo\\lib\\site-packages\\scipy\\optimize\\_optimize.py:353: RuntimeWarning: Values in x were outside bounds during a minimize step, clipping to bounds\n",
      "  warnings.warn(\"Values in x were outside bounds during a \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       " message: Optimization terminated successfully\n",
       " success: True\n",
       "  status: 0\n",
       "     fun: 1365.9152749593097\n",
       "       x: [ 3.885e+00  4.044e-01  3.639e-01  2.752e+00  1.000e-01\n",
       "            9.483e+00  1.000e-01  1.063e+02]\n",
       "     nit: 40\n",
       "     jac: [ 5.492e+02  6.352e+01  1.573e+03  1.040e+02  0.000e+00\n",
       "            0.000e+00  1.284e+02  0.000e+00]\n",
       "    nfev: 52\n",
       "    njev: 40"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minimize(obj_function, xguess, bounds=bnds_problem, jac=dobj, \n",
    "         constraints=constraints, method='SLSQP', options={'maxiter':1000})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.48, 3.88, 0.2, 0.3, 0.4, 0.36, 0.09, 0.1, 2.75, 1, 9.8, 1000, 1,\n",
       "       1, 1, 0.1, 1, 1, 1, 1, 1, 1, 1, 1, 10, 1, 106.29, 50, 50, 1, 700,\n",
       "       2700, 1, 1, 0.75, 1, 1, 300000000, 2200000000, 1, 27, 32, 1, 0.55,\n",
       "       1, 5.3, 1, 6378000, 600000, 1, 1, 38.9, 0.93, 0.79, 0.93, 85000000,\n",
       "       135, 0, 1, 3600, 1, 50, 86400, 1, 3600, 1, 1900, 1, 1, 43200, 1, 1,\n",
       "       1, 43200, 1, 0.9, 1, 0.05, 0.27, 800, 0.96, 0.7, 1, 0.85, 1, 5,\n",
       "       720000])"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x0.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([1346.1686], dtype=torch.float64),\n",
       " tensor([-9.9000e-01, -3.4117e-13, -9.7506e-01, -1.1635e+04,  5.4655e-11],\n",
       "        dtype=torch.float64),\n",
       " tensor([8.1712e-14], dtype=torch.float64),\n",
       " tensor([-4.8590e-11, -8.1823e-14, -7.8271e-14], dtype=torch.float64)]"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf_eval(x0.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([1346.1686], dtype=torch.float64, grad_fn=<IndexBackward0>),\n",
       " tensor([-9.9000e-01, -3.4117e-13, -9.7506e-01, -1.1635e+04,  6.4256e-11],\n",
       "        dtype=torch.float64, grad_fn=<CatBackward0>),\n",
       " tensor([9.7700e-14], dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor([-9.6002e-12, -1.5876e-14, -1.4988e-14], dtype=torch.float64,\n",
       "        grad_fn=<CatBackward0>)]"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf_eval(all_sequential(x0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "xsol = all_sequential(x0).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_solar D_f  alpha d     D_d D_s   h_f  t_d t_s   V_d   g   rho_w F_B    F_W    K_B   t_f K_G I      B_M   G_M   C_33   A_33   m_platform \\omega_0 eta_solar m_solar m_batt  m_comms m_prop m_struct rho rho_h S_w    C_d eta_m v P_move c      f      l     e_t theta_t L_pt eta_parab G_t    D_r G_r     R_e    h      S      L_s      E_N  L_a   L_l  L_p   R      T_s k        P_comms t_move E_move P_hotel t_mission E_hotel t_comms E_comms E_AUV G E_service t_service P_service E_required E_recharge t_recharge P_recharge I_deg L_solar d_deg eta_s phi_s theta DOD N_batt eta_battery C      m_battzero mu_battery\n",
      "10.101  4.01 0.2   0.802 0.1 0.224 0.09 0.1 5.282 1.346 9.8 1000  1.32e4 1.32e4 3.346 0.1 3.4 12.686 9.424 9.371 1.24e5 1.06e4 1346.169   5.818    10        101.01  112.886 50      50     1032.272 700 2700  17.453 1   0.75  1 1.16e4 3.00e8 2.20e9 0.136 27  32      0.14 0.55      26.255 5.3 8200.06 6.38e6 6.00e5 2.83e6 1.47e-17 38.9 0.933 0.79 0.933 8.50e7 135 1.38e-23 2.833   3600   4.19e7 50      8.64e4    4.32e6  3600    1.02e4  1900  1 1900      4.32e4    0.044     4.62e7     4.62e7     4.32e4     1069.873   0.9   1       0.05  0.27  800   0.96  0.7 1      0.85        7.77e7 5          7.20e5    \n"
     ]
    }
   ],
   "source": [
    "def custom_formatter(x):\n",
    "    if abs(x) < 0.01:\n",
    "        return \"{:.2e}\".format(x).replace('+0', '')\n",
    "    elif abs(x) > 10000:\n",
    "        return \"{:.2e}\".format(x).replace('+0', '')\n",
    "    else:\n",
    "        return \"{:.3f}\".format(x).rstrip('0').rstrip('.')\n",
    "    \n",
    "matrix =([str(k) for k in indices.keys()], xsol)\n",
    "col_widths = [max(len(custom_formatter(row1)), len(name)) for name,row1 in zip(*matrix)]\n",
    "print(\" \".join(\"{:<{}}\".format(name, width) for name, width in zip(matrix[0], col_widths)))\n",
    "for row in matrix[1:]:\n",
    "    print(\" \".join(\"{:<{}}\".format(custom_formatter(num), width) for num, width in zip(row, col_widths)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "noelim = ParallelAnalysis(list(sequential.values()), [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2,  3,  9, 12, 13, 14, 16, 17, 18, 19, 20, 21, 23, 22, 25, 29,  8, 32,\n",
       "        36, 39, 42, 44, 46, 49, 50, 58, 60, 63, 65, 68, 70, 71, 72, 74,  1, 84,\n",
       "        26])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(noelim.sharedvars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sequential = EliminateAnalysis(list(sequential.values()), [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0,  1,  4,  5,  6,  7,  8, 10, 11, 15, 22, 24, 26, 27, 28, 30, 31, 33,\n",
       "         34, 35, 37, 38, 40, 41, 43, 45, 47, 48, 51, 52, 53, 54, 55, 56, 57, 59,\n",
       "         61, 62, 64, 66, 67, 69, 73, 75, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86]),\n",
       " tensor([ 2,  3,  9, 12, 13, 14, 16, 17, 18, 19, 20, 21, 23, 22, 25, 29,  8, 32,\n",
       "         36, 39, 42, 44, 46, 49, 50, 58, 60, 63, 65, 68, 70, 71, 72, 74,  1, 84,\n",
       "         26]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_sequential.structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(1), tensor(8), tensor(22), tensor(26)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "couplingvars = [elt for elt in all_sequential.structure[0] if elt in all_sequential.structure[1]]\n",
    "couplingvars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = ParallelAnalysis([all_sequential],[], sharedvars=couplingvars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0,  1,  4,  5,  6,  7,  8, 10, 11, 15, 22, 24, 26, 27, 28, 30, 31, 33,\n",
       "         34, 35, 37, 38, 40, 41, 43, 45, 47, 48, 51, 52, 53, 54, 55, 56, 57, 59,\n",
       "         61, 62, 64, 66, 67, 69, 73, 75, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86]),\n",
       " ())"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "residuals.structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graph.graphutils import all_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(43)\n",
    "all_indices = torch.cat(list(indices.values()))\n",
    "x0 = torch.zeros_like(all_indices, dtype=torch.float64)\n",
    "# only set entries corresponding to variables specified in a dict e.g. {D_f:1.0}\n",
    "# to the value specified in the dict\n",
    "numerical_values = {'D_f': 1.0, 'D_d':1.0, 'D_s':1.0, 't_d':4/3, 'h_f':4/3, 't_s':4/3}\n",
    "for var, val in numerical_values.items():\n",
    "    x0[indices[sp.symbols(var)]] = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchengine import EliminateAnalysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "minimdo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
