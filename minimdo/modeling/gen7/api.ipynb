{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modeling.gen6.api import symbolic, get_constraints\n",
    "from engine.torchengine import EliminateAnalysis, ParallelResiduals, ElimResidual, ipoptsolver\n",
    "from functools import partial\n",
    "from engine.torchdata import load_vals, print_formatted_table\n",
    "import torch\n",
    "import uuid, base64\n",
    "\n",
    "def generate_short_id():\n",
    "    # Generate a UUID\n",
    "    full_uuid = uuid.uuid4()\n",
    "    # Convert UUID to bytes and encode in base64\n",
    "    uuid_bytes = full_uuid.bytes\n",
    "    encoded = base64.urlsafe_b64encode(uuid_bytes)\n",
    "    # Take first 8 characters and remove any base64 padding\n",
    "    short_id = encoded[:8].decode('ascii').rstrip('=')\n",
    "    return short_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to have identifiers to sets \n",
    "# then architectures point to sets instances (or architectures) through constraints/elimination/parallel\n",
    "# then set instances (a set with a specific choice of representation function) are built; this is because we need to generate the indices set that is consistent for all set instances (i.e. dimensions)\n",
    "# this allows for flexibility in building, and efficicency when computing (i.e. we have fixed the dimension of the problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build(architecture, sets, indices):\n",
    "    # sets_default, indices_default = self.get_sets()\n",
    "    # if sets is None:\n",
    "    #     sets = sets_default\n",
    "    # if indices is None:\n",
    "    #     indices = indices_default\n",
    "    if not architecture.parallel and not architecture.elim:\n",
    "        if len(architecture.constraints) == 1:\n",
    "            cid, _ = architecture.constraints[0]\n",
    "            return sets[cid].analysis\n",
    "        else:\n",
    "            return EliminateAnalysis([sets[cid].analysis for cid,_ in architecture.constraints])\n",
    "    else:\n",
    "        if architecture.parallel:\n",
    "            parallel_sets = [build(mfs, sets, indices) for mfs in architecture.parallel]\n",
    "            T = ParallelResiduals(analyses=parallel_sets, functions=[])\n",
    "            R = EliminateAnalysis([build(mfs, sets, indices) for mfs in architecture.elim], [T], flatten=True)\n",
    "            solvefor = torch.tensor([p.structure[1] for p in parallel_sets])\n",
    "            bnds = [(None, None) for _ in solvefor]\n",
    "            ipsolver = partial(ipoptsolver, bnds_problem=bnds)\n",
    "            S = ElimResidual(R, solvefor, indices, \n",
    "                    solver=ipsolver,\n",
    "                    solvefor_raw=True)\n",
    "            return S\n",
    "        else:\n",
    "            return EliminateAnalysis([build(mfs, sets, indices) for mfs in architecture.elim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MFunctionalSet():\n",
    "    def __init__(self, *constraints):\n",
    "        self.constraints = [(generate_short_id(), c) for c in constraints] if constraints is not None else []\n",
    "        self.elim = []\n",
    "        self.parallel = []\n",
    "\n",
    "    def functionalsubsetof(self, *constraints):\n",
    "        self.constraints += constraints\n",
    "        return self\n",
    "    \n",
    "    def gather_sets(self):\n",
    "        all_constraints = []\n",
    "        constraints = list(self.constraints) #deep copy\n",
    "        counter = 0\n",
    "        while constraints:\n",
    "            counter += 1\n",
    "            c = constraints.pop()\n",
    "            if hasattr(c, \"constraints\"):\n",
    "                constraints += c.constraints\n",
    "            else:\n",
    "                all_constraints.append(c)\n",
    "        sets, _, _, indices = get_constraints(all_constraints)\n",
    "        return sets, indices\n",
    "\n",
    "    def config(self, elim=None, parallel=None):\n",
    "        if elim is None and parallel is None:\n",
    "            return self\n",
    "        MFS = MFunctionalSet(self.constraints)\n",
    "        MFS.elim = elim if elim is not None else []\n",
    "        MFS.parallel = parallel if parallel is not None else []\n",
    "        return MFS\n",
    "    \n",
    "    \n",
    "    def build(self, sets=None, indices=None):\n",
    "        return build(self, sets, indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x, y, z, y1, y2, y3, z1, z2 = symbolic(\"x\", \"y\", \"z\", \"y1\", \"y2\", \"y3\", \"z1\", \"z2\")\n",
    "x, y, z, a, b, c, d = symbolic(\"x\", \"y\", \"z\", \"a\", \"b\", \"c\", \"d\")\n",
    "\n",
    "S1 = MFunctionalSet(x + y == a)\n",
    "S2 = MFunctionalSet(d == 2*a)\n",
    "S3 = MFunctionalSet(x == a+d)\n",
    "D1 = MFunctionalSet().functionalsubsetof(S1, S2, S3)\n",
    "S4 = MFunctionalSet(c == a+b)\n",
    "D2 = MFunctionalSet().functionalsubsetof(D1, S4)\n",
    "\n",
    "set_info = D2.gather_sets()\n",
    "sets, indices = set_info\n",
    "# MD = D2.config(elim=[D1.config(elim=[S1], parallel=[S2]), S3]).build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = {'x': 1, 'y': 2, 'b': 3}\n",
    "x = load_vals(x0, indices, isdict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.,  2.,  3., -1., -3.,  2.], dtype=torch.float64)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aD2a = D2.config(elim=[D1.config(parallel=[S1, S2, S3]), S4]).build(*set_info)\n",
    "xfp = aD2a(x)\n",
    "xfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.,  2.,  0., -1., -3., -1.], dtype=torch.float64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aD2b = D2.config(elim=[D1.config(elim=[S1, S2, S3]), S4]).build(*set_info)\n",
    "aD2b(xfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d  y b a  x  c\n",
      "-2 2 3 -1 -3 2\n"
     ]
    }
   ],
   "source": [
    "idxrev = {var.item():key for key,var in indices.items()}\n",
    "print_formatted_table([xfp], indices, idxrev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 3., 2., 0., 2.], dtype=torch.float64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aD1 = D1.config(elim=[S1, S2]).build(sets)\n",
    "aD1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s, indices = D2.get_sets()\n",
    "A1 = S1.build(s, indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1: Instantiate directly from config: C1.config(eliminate=[C2.config(),D1.config()], parallel=[C4,C5])\n",
    "# F2: store information: C1.children = [C2,D1,C4,C5]; A1.children=[C5,C6]\n",
    "# F3: preprocess: e.g. C1.flatten() -> new store information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "A,V,S,W,Ww,CL,Re,Cf,CD,D = symbolic('A','V','S','W','Ww','C_L','Re','C_f','C_D','D')\n",
    "rho,mu,k,t,e,CDA,SwetS,W0,pi = 1.23, 1.78e-5, 1.2, 0.12, 0.96, 0.0306, 2.05, 4940, 3.14\n",
    "\n",
    "Aero = MFunctionalSet(\n",
    "    CL == 2*W/(rho*V**2*S),\n",
    "    Re == rho*V/mu*(S/A)**(1/2),\n",
    "    Cf == 0.074/Re**0.2,\n",
    "    CD == CDA/S+k*Cf*SwetS+CL**2/(3.14*A*e),\n",
    "    D == 0.5*rho*V**2*CD*S\n",
    ")\n",
    "Struct1 = MFunctionalSet(\n",
    "    Ww == 45.42*S+8.71e-5*2.5/t*A**(3/2)*S**(1/2)*(W0*W)**(1/2),\n",
    ")\n",
    "Struct2 = MFunctionalSet(\n",
    "    W == W0+Ww\n",
    ")\n",
    "\n",
    "Struct = MFunctionalSet().functionalsubsetof(Struct1, Struct2)\n",
    "AeroStruct = MFunctionalSet().functionalsubsetof(Aero, Struct1, Struct2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_info = AeroStruct.gather_sets()\n",
    "sets, indices = set_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = {'A': 18.16, 'V': 49.18, 'S': 5.256, 'W':7000}\n",
    "x = load_vals(x0, indices, isdict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "xfp = Struct.config(parallel=[Struct1, Struct2]).build(*set_info)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C_f    C_D    C_L    A     Re     W        S     V     Ww       D     \n",
      "0.00e0 0.00e0 0.00e0 18.16 0.00e0 7083.108 5.256 49.18 2143.108 0.00e0\n"
     ]
    }
   ],
   "source": [
    "print_formatted_table([xfp], indices, idxrev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "xfp = Aero.build(*set_info)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C_f      C_D  C_L   A  Re     W    S V  Ww     D      \n",
      "4.19e-03 0.03 0.911 20 1.73e6 7000 5 50 0.00e0 231.926\n"
     ]
    }
   ],
   "source": [
    "print_formatted_table([xfp], indices, idxrev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config 1\n",
    "C1 = AeroStruct.config(elim=[Struct.config(parallel=[Struct1, Struct2]), Aero]).build(*set_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "xfp = C1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C_f      C_D   C_L   A     Re     W        S     V     Ww       D      \n",
      "4.14e-03 0.031 0.906 18.16 1.83e6 7083.108 5.256 49.18 2143.108 242.334\n"
     ]
    }
   ],
   "source": [
    "idxrev = {var.item():key for key,var in indices.items()}\n",
    "print_formatted_table([xfp], indices, idxrev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config 2\n",
    "C2 = AeroStruct.config(elim=[Aero, Struct1], residual=[Struct2]).build()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "minimdo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
